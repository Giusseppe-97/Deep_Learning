To build your neural network, you'll be implementing several "helper functions." 
These helper functions will be used in the next assignment to build a two-layer neural network and an L-layer neural network.

Each small helper function will have detailed instructions to walk you through the necessary steps. Here's an outline of the steps in this assignment:

	Initialize the parameters for a two-layer network and for an  ð¿ -layer neural network
	Implement the forward propagation module (shown in purple in the figure below)
		Complete the LINEAR part of a layer's forward propagation step (resulting in  ð‘[ð‘™] ).
		The ACTIVATION function is provided for you (relu/sigmoid)
		Combine the previous two steps into a new [LINEAR->ACTIVATION] forward function.
		Stack the [LINEAR->RELU] forward function L-1 time (for layers 1 through L-1) and add a [LINEAR->SIGMOID] at the end (for the final layer  ð¿ ). 
		This gives you a new L_model_forward function.
	Compute the loss
	Implement the backward propagation module (denoted in red in the figure below)
		Complete the LINEAR part of a layer's backward propagation step
		The gradient of the ACTIVATE function is provided for you(relu_backward/sigmoid_backward)
		Combine the previous two steps into a new [LINEAR->ACTIVATION] backward function
		Stack [LINEAR->RELU] backward L-1 times and add [LINEAR->SIGMOID] backward in a new L_model_backward function
		Finally, update the parameters